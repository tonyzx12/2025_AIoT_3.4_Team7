# ESP32-P4-EYE Train & Apply Custom YOLO Model Guide (Work in Progress)

This guide covers the complete workflow for training a custom YOLO11 object detection model on AWS SageMaker and deploying it to ESP32-P4-EYE.

table of Contents:
- [overall steps](#overall-steps)
- [prepare dataset](#prepare-dataset)
- [SageMaker Training Job](#sagemaker-training-job)
- [Convert And Deploy](#convert-and-deploy)

## overall steps
```
Dataset (Roboflow)
â†“
Download & Prepare
â†“
Upload to S3
â†“
SageMaker Training Job (GPU)
â†“
Download best.pt
â†“
Convert to .onnx, .espdl format
â†“
Flash to ESP32-P4-EYE
```

## prepare dataset

1. Go to Roboflow and find your dataset
    ![alt text](img/image3.png)

    ![alt text](img/image4.png)

    folder structure should be like this:
    ```
    â”œâ”€â”€ data.yaml
    â”œâ”€â”€ images/
    â”‚Â Â  â”œâ”€â”€ train/
    â”‚   â”‚   â”œâ”€â”€ img001.jpg
    â”‚   â”‚   â”œâ”€â”€ img002.jpg
    â”‚   â”‚   â””â”€â”€ ...
    â”‚Â Â  â””â”€â”€ val/
    â”‚       â”œâ”€â”€ img101.jpg
    â”‚       â””â”€â”€ ...    
    â”œâ”€â”€ labels/
    â”‚Â Â  â”œâ”€â”€ train/
    â”‚   â”‚   â”œâ”€â”€ img001.txt
    â”‚   â”‚   â”œâ”€â”€ img002.txt
    â”‚   â”‚   â””â”€â”€ ...
    â”‚Â Â  â””â”€â”€ val/
    â”‚       â”œâ”€â”€ img101.txt
    â”‚       â””â”€â”€ ...
    ```

2. upload the zip file to your S3 bucket
    ![alt text](img/image5.png)

    ![alt text](img/image6.png)


## SageMaker Training Job

æ­¤ Notebook æœƒï¼š
1. ç”Ÿæˆè¨“ç·´ç¨‹å¼ `train.py` èˆ‡ `requirements.txt`
2. ä»¥ **SageMaker PyTorch Estimator** å•Ÿå‹• Training Job
3. åœ¨ Notebook å…§**ä¸²æµé¡¯ç¤ºè¨“ç·´æ—¥èªŒ**ï¼Œä¸¦**å˜—è©¦å‹•æ…‹è§£ææ¯å€‹ epoch æŒ‡æ¨™ï¼Œç•«å‡ºæ”¶æ–‚æ›²ç·š**
4. è¨“ç·´å®Œæˆå¾Œä¸‹è¼‰ artifactsï¼ˆå« `best.pt`ã€`runs/`ã€`results.csv`ã€`results.png`ï¼‰ä¸¦é¡¯ç¤ºå®Œæ•´æ›²ç·š

> æ³¨æ„ï¼šå‹•æ…‹æ›²ç·šè§£æä¾è³´ Ultralytics æ—¥èªŒæ ¼å¼ï¼›è‹¥ç‰ˆæœ¬è¼¸å‡ºä¸åŒï¼Œå¯èƒ½è§£æä¸åˆ°ï¼Œä½†**è¨“ç·´å®Œæˆå¾Œ**ä¸€å®šèƒ½ç”¨ `results.csv/results.png` ç•«å‡ºå®Œæ•´æ”¶æ–‚æ›²ç·šã€‚

> ğŸš© å…ˆåŸ·è¡Œ: `!pip install -U ultralytics opencv-python`

## 0) å…ˆæ±ºæ¢ä»¶

- å·²åœ¨ SageMaker Studio / Notebook Instance åŸ·è¡Œ
- IAM role å…·å‚™ SageMaker èˆ‡ S3 æ¬Šé™
- ä½ å·²æŠŠ YOLO æ ¼å¼è³‡æ–™é›†æ‰“åŒ…æˆ zip æ”¾åœ¨ S3

è³‡æ–™ zip å…§éƒ¨å»ºè­°çµæ§‹ï¼š
```
mydata/
  images/train
  images/val
  labels/train
  labels/val
```



```python
import os, json, tarfile, re, time
from pathlib import Path

import boto3
import sagemaker
from sagemaker.pytorch import PyTorch
from sagemaker.inputs import TrainingInput
from sagemaker.s3 import S3Downloader

import pandas as pd
import matplotlib.pyplot as plt
from IPython.display import display, clear_output, Image

sess = sagemaker.Session()
region = sess.boto_region_name
role = sagemaker.get_execution_role()
sm = boto3.client('sagemaker', region_name=region)
logs = boto3.client('logs', region_name=region)

print('region:', region)
print('default bucket:', sess.default_bucket())

```

    region: us-east-1
    default bucket: sagemaker-us-east-1-049281306005


### 1) åƒæ•¸è¨­å®šï¼ˆè«‹æ”¹æˆä½ çš„ S3 è·¯å¾‘èˆ‡é¡åˆ¥åç¨±ï¼‰


```python
# ====== ä½ è¦æ”¹çš„åœ°æ–¹ ======
S3_DATA_ZIP = 's3://2025team1/dataset/mobile_detect.yolov11.zip'  # <<<<<< æ”¹æˆä½ çš„è³‡æ–™é›†
DATA_ZIP_FILENAME = 'mobile_detect.yolov11.zip'           # zip æª”å

# é¡åˆ¥åç¨±ï¼ˆè«‹æ”¹æˆä½ çš„ classesï¼‰
CLASS_NAMES = ['class0', 'class1']

# YOLO11 æ¬Šé‡ï¼ˆå¯æ”¹ yolo11s.pt / yolo11m.pt / yolo11l.pt / yolo11x.ptï¼‰
YOLO_MODEL = 'yolo11n.pt'

# è¨“ç·´è¶…åƒæ•¸
EPOCHS = 50
IMGSZ = 640
BATCH = 16
WORKERS = 4

# è¨“ç·´ç¡¬é«”ï¼ˆæ¨è–¦ GPUï¼šg5 / g4dnï¼‰
INSTANCE_TYPE = 'ml.g5.2xlarge'
INSTANCE_COUNT = 1

# è¼¸å‡ºåˆ° S3
OUTPUT_S3 = f"s3://2025team1/output/"

print('S3_DATA_ZIP:', S3_DATA_ZIP)
print('OUTPUT_S3:', OUTPUT_S3)

```

    S3_DATA_ZIP: s3://2025team1/dataset/mobile_detect.yolov11.zip
    OUTPUT_S3: s3://2025team1/output/


### 2) ç”Ÿæˆè¨“ç·´ç¨‹å¼ç¢¼ï¼ˆtrain.pyï¼‰èˆ‡ requirements.txt

é‡é»ï¼š
- SageMaker æœƒæŠŠ `training` channel æ›è¼‰åœ¨ `/opt/ml/input/data/training/`
- ä½ è¦æŠŠ artifacts å¯«åˆ° `/opt/ml/model/`ï¼ŒSageMaker æ‰æœƒä¸Šå‚³åˆ° `output_path`
- æˆ‘å€‘æŠŠ Ultralytics çš„ `runs/` æ”¾åˆ° `/opt/ml/model/runs/`ï¼Œæ–¹ä¾¿äº‹å¾Œä¸‹è¼‰ `results.csv` / `results.png`



```python
src_dir = Path('src')
src_dir.mkdir(exist_ok=True)

train_py = r'''
import argparse
import base64
import json
import zipfile
import shutil
from pathlib import Path
import yaml
from ultralytics import YOLO

def main():
    p = argparse.ArgumentParser()
    p.add_argument('--data_zip', type=str, default='mydata.zip')
    p.add_argument('--model', type=str, default='yolo11n.pt')
    p.add_argument('--epochs', type=int, default=50)
    p.add_argument('--imgsz', type=int, default=640)
    p.add_argument('--batch', type=int, default=16)
    p.add_argument('--workers', type=int, default=4)

    # âœ… æ”¹æˆ base64ï¼Œé¿å… argv è¢«æ‹†
    p.add_argument('--class_names_b64', type=str, required=True)

    args = p.parse_args()

    # âœ… è§£ç¢¼å› list[str]
    class_names = json.loads(base64.b64decode(args.class_names_b64).decode("utf-8"))

    sm_data_dir = Path('/opt/ml/input/data/training')
    sm_model_dir = Path('/opt/ml/model')
    sm_model_dir.mkdir(parents=True, exist_ok=True)

    work_dir = Path('/tmp/data')
    work_dir.mkdir(parents=True, exist_ok=True)

    zip_path = sm_data_dir / args.data_zip
    with zipfile.ZipFile(zip_path, 'r') as z:
        z.extractall(work_dir)

    entries = [d for d in work_dir.iterdir() if d.is_dir()]
    dataset_root = entries[0] if entries else work_dir

    data_yaml = {
        'path': str(dataset_root),
        'train': 'images/train',
        'val': 'images/val',
        'names': class_names,
    }
    yaml_path = work_dir / 'data.yaml'
    with open(yaml_path, 'w') as f:
        yaml.safe_dump(data_yaml, f)

    model = YOLO(args.model)
    project_dir = sm_model_dir / 'runs'
    model.train(
        data=str(yaml_path),
        epochs=args.epochs,
        imgsz=args.imgsz,
        batch=args.batch,
        workers=args.workers,
        project=str(project_dir),
        name='train',
        verbose=True,
    )

    best_pt = project_dir / 'train' / 'weights' / 'best.pt'
    if best_pt.exists():
        shutil.copy2(best_pt, sm_model_dir / 'best.pt')

if __name__ == '__main__':
    main()

'''

(src_dir / 'train.py').write_text(train_py, encoding='utf-8')
(src_dir / 'requirements.txt').write_text('ultralytics\nopencv-python\npyyaml\n', encoding='utf-8')
print('Wrote:', src_dir / 'train.py')
print('Wrote:', src_dir / 'requirements.txt')

```

    Wrote: src/train.py
    Wrote: src/requirements.txt


### 3) å»ºç«‹ Estimator ä¸¦å•Ÿå‹• Training Jobï¼ˆéé˜»å¡ï¼‰


```python
import base64, json

class_names_b64 = base64.b64encode(
    json.dumps(CLASS_NAMES, ensure_ascii=False).encode("utf-8")
).decode("ascii")

hyperparameters = {
    "data_zip": DATA_ZIP_FILENAME,
    "model": YOLO_MODEL,
    "epochs": EPOCHS,
    "imgsz": IMGSZ,
    "batch": BATCH,
    "workers": WORKERS,
    "class_names_b64": class_names_b64,
}

est = PyTorch(
    entry_point='train.py',
    source_dir=str(src_dir),
    role=role,
    framework_version='2.2',
    py_version='py310',
    instance_count=INSTANCE_COUNT,
    instance_type=INSTANCE_TYPE,
    hyperparameters=hyperparameters,
    output_path=OUTPUT_S3,
)

job_name = f"yolo11-train-{int(time.time())}"
print('TrainingJobName:', job_name)

est.fit(
    inputs={'training': TrainingInput(S3_DATA_ZIP, content_type='application/zip')},
    job_name=job_name,
    wait=False,
)
print('å·²é€å‡º Training Jobã€‚æ¥è‘—è·‘ä¸‹ä¸€æ ¼é–‹å§‹å‹•æ…‹ç›£æ§ã€‚')

```

    INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.
    To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.
    INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.
    INFO:sagemaker:Creating training-job with name: yolo11-train-1767630997


    TrainingJobName: yolo11-train-1767630997
    å·²é€å‡º Training Jobã€‚æ¥è‘—è·‘ä¸‹ä¸€æ ¼é–‹å§‹å‹•æ…‹ç›£æ§ã€‚


### 4) å‹•æ…‹é¡¯ç¤ºè¨“ç·´éç¨‹èˆ‡æ”¶æ–‚æ›²ç·šï¼ˆå³æ™‚ï¼‰

æœƒå¾ CloudWatch Logs æ‹‰å–æœ€æ–°æ—¥èªŒä¸¦å˜—è©¦è§£æ epoch æŒ‡æ¨™ã€‚



```python
import boto3, re

logs = boto3.client("logs", region_name=region)

def list_sagemaker_log_groups(prefix_hint="/aws/sagemaker"):
    resp = logs.describe_log_groups(logGroupNamePrefix=prefix_hint, limit=50)
    return [g["logGroupName"] for g in resp.get("logGroups", [])]

print("\n".join(list_sagemaker_log_groups()))
desc = sm.describe_training_job(TrainingJobName=job_name)
print("TrainingJobArn =", desc["TrainingJobArn"])

```

    /aws/sagemaker/NotebookInstances
    /aws/sagemaker/TrainingJobs
    TrainingJobArn = arn:aws:sagemaker:us-east-1:049281306005:training-job/yolo11-train-1767630997



```python
import time
import re
import pandas as pd
import matplotlib.pyplot as plt
import boto3
from IPython.display import display, clear_output

# ------------------------------------------------------------
# 1) å…ˆç”¨åŸæœ¬çš„ sm å–å¾— TrainingJobArnï¼Œåæ¨å‡º job çš„ region
# ------------------------------------------------------------
desc = sm.describe_training_job(TrainingJobName=job_name)
training_job_arn = desc["TrainingJobArn"]
job_region = training_job_arn.split(":")[3]

print("TrainingJobArn:", training_job_arn)
print("Job region    :", job_region)

# ------------------------------------------------------------
# 2) ç”¨ã€Œjob çš„ regionã€é‡æ–°å»ºç«‹ clientsï¼ˆé—œéµä¿®æ­£é»ï¼‰
# ------------------------------------------------------------
logs = boto3.client("logs", region_name=job_region)
sm2  = boto3.client("sagemaker", region_name=job_region)

print("CloudWatch logs region =", logs.meta.region_name)
print("SageMaker client region =", sm2.meta.region_name)

# ------------------------------------------------------------
# 3) é‡æ–°å®šç¾© helper functionsï¼ˆåªå·®åœ¨ç”¨ sm2 / logsï¼‰
# ------------------------------------------------------------
def get_training_job_status(job_name: str):
    d = sm2.describe_training_job(TrainingJobName=job_name)
    return d["TrainingJobStatus"], d

def find_log_stream(job_name: str, log_group="/aws/sagemaker/TrainingJobs"):
    paginator = logs.get_paginator("describe_log_streams")
    for page in paginator.paginate(
        logGroupName=log_group,
        logStreamNamePrefix=job_name
    ):
        streams = page.get("logStreams", [])
        if streams:
            streams = sorted(
                streams,
                key=lambda s: s.get("lastEventTimestamp", 0),
                reverse=True
            )
            return streams[0]["logStreamName"]
    return None

def fetch_logs(log_group, log_stream, next_token=None):
    kwargs = dict(
        logGroupName=log_group,
        logStreamName=log_stream,
        startFromHead=True
    )
    if next_token:
        kwargs["nextToken"] = next_token
    resp = logs.get_log_events(**kwargs)
    return resp.get("events", []), resp.get("nextForwardToken")

# ------------------------------------------------------------
# 4) epoch log best-effort parserï¼ˆä¸è®Šï¼‰
# ------------------------------------------------------------
epoch_metrics = []
epoch_line_re = re.compile(
    r"^\s*(\d+)\s+([0-9.eE+-]+)\s+([0-9.eE+-]+)\s+([0-9.eE+-]+)\s+([0-9.eE+-]+)\s+([0-9.eE+-]+)"
)

def try_parse_epoch_line(msg: str):
    m = epoch_line_re.match(msg)
    if not m:
        return None
    epoch = int(m.group(1))
    vals = [float(m.group(i)) for i in range(2, 7)]
    return {
        "epoch": epoch,
        "v1": vals[0],
        "v2": vals[1],
        "v3": vals[2],
        "v4": vals[3],
        "v5": vals[4],
    }

# ------------------------------------------------------------
# 5) æ‰¾ log streamï¼ˆç¾åœ¨ä¸€å®šåœ¨æ­£ç¢º regionï¼‰
# ------------------------------------------------------------
log_group = "/aws/sagemaker/TrainingJobs"
log_stream = None
token = None
seen = set()
tail = []

print("å°‹æ‰¾ CloudWatch Log Stream...")
for _ in range(60):
    log_stream = find_log_stream(job_name, log_group=log_group)
    if log_stream:
        break
    time.sleep(5)

if not log_stream:
    raise RuntimeError(
        f"æ‰¾ä¸åˆ° log streamï¼ˆjob_name={job_name}ï¼Œregion={job_region}ï¼‰"
    )

print("log_group :", log_group)
print("log_stream:", log_stream)

# ------------------------------------------------------------
# 6) å³æ™‚ç›£æ§ + å‹•æ…‹æ”¶æ–‚æ›²ç·š
# ------------------------------------------------------------
while True:
    status, desc = get_training_job_status(job_name)

    events, token = fetch_logs(log_group, log_stream, token)
    new_lines = []

    for e in events:
        key = (e.get("timestamp"), e.get("message"))
        if key in seen:
            continue
        seen.add(key)

        msg = (e.get("message") or "").rstrip("\n")
        if not msg:
            continue

        new_lines.append(msg)

        parsed = try_parse_epoch_line(msg)
        if parsed:
            if not epoch_metrics or parsed["epoch"] != epoch_metrics[-1]["epoch"]:
                epoch_metrics.append(parsed)

    tail = (tail + new_lines)[-50:]

    clear_output(wait=True)
    print("TrainingJob:", job_name)
    print("Status     :", status)
    print("Region     :", job_region)
    print("----- logs tail -----")
    for line in tail:
        print(line)

    if len(epoch_metrics) >= 2:
        df_live = pd.DataFrame(epoch_metrics).sort_values("epoch")
        display(df_live.tail(10))

        plt.figure()
        plt.plot(df_live["epoch"], df_live["v1"], label="v1")
        plt.plot(df_live["epoch"], df_live["v2"], label="v2")
        plt.plot(df_live["epoch"], df_live["v3"], label="v3")
        plt.xlabel("epoch")
        plt.legend()
        plt.title("Live convergence (parsed from CloudWatch logs)")
        plt.show()

    if status in ["Completed", "Failed", "Stopped"]:
        print("\nTraining job finished with status:", status)
        if status != "Completed":
            print("FailureReason:", desc.get("FailureReason"))
        break

    time.sleep(10)

```

    TrainingJob: yolo11-train-1767630997
    Status     : Completed
    Region     : us-east-1
    ----- logs tail -----
    ...
    all         39         39      0.972          1      0.994      0.928
    Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
    #033[K      50/50      2.61G      0.256     0.4896     0.7991         16        640: 11% â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/9 1.9it/s 0.2s<4.2s
    #033[K      50/50      2.61G     0.2598      0.483     0.8168         16        640: 22% â”â”â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2/9 4.0it/s 0.3s<1.7s
    #033[K      50/50      2.61G     0.2738     0.5036     0.8141         16        640: 44% â”â”â”â”â”â”€â”€â”€â”€â”€â”€â”€ 4/9 6.5it/s 0.4s<0.8s
    #033[K      50/50      2.61G     0.2629     0.4972     0.8201         17        640: 67% â”â”â”â”â”â”â”â”â”€â”€â”€â”€ 6/9 7.8it/s 0.6s<0.4s
    #033[K      50/50      2.61G     0.2516     0.4929     0.8156         13        640: 89% â”â”â”â”â”â”â”â”â”â”â•¸â”€ 8/9 9.2it/s 0.8s<0.1s#015#033[K      50/50      2.61G     0.2516     0.4929     0.8156         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 11.6it/s 0.8s#015#033[K      50/50      2.61G     0.2516     0.4929     0.8156         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 11.6it/s 0.8s
    #033[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 1/2 2.8it/s 0.1s<0.4s
    #033[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 13.3it/s 0.2s#015#033[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 13.3it/s 0.2s
    all         39         39      0.974          1      0.994      0.938
    50 epochs completed in 0.018 hours.
    ...
    Results saved to #033[1m/opt/ml/model/runs/train#033[0m
    2026-01-05 16:42:47,154 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.
    2026-01-05 16:42:47,154 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.
    2026-01-05 16:42:47,154 sagemaker-training-toolkit INFO     Reporting training SUCCESS
    
    Training job finished with status: Completed


### 5) ä¸‹è¼‰ artifacts ä¸¦ç•«å‡ºå®Œæ•´æ”¶æ–‚æ›²ç·šï¼ˆresults.csv / results.pngï¼‰


```python
while True:
    status, _ = get_training_job_status(job_name)
    if status in ['Completed', 'Failed', 'Stopped']:
        print('Final status:', status)
        break
    time.sleep(20)

if status != 'Completed':
    raise RuntimeError(f'Training job not completed: {status}')

desc = sm.describe_training_job(TrainingJobName=job_name)
model_artifact = desc['ModelArtifacts']['S3ModelArtifacts']
print('Model artifact:', model_artifact)

out_dir = Path('artifacts') / job_name
out_dir.mkdir(parents=True, exist_ok=True)

S3Downloader.download(model_artifact, str(out_dir))
local_tar = out_dir / 'model.tar.gz'
print('Downloaded:', local_tar)

with tarfile.open(local_tar, 'r:gz') as t:
    t.extractall(path=out_dir)

best_pt = out_dir / 'best.pt'
results_png = out_dir / 'runs' / 'train' / 'results.png'
results_csv = out_dir / 'runs' / 'train' / 'results.csv'

print('best.pt exists:', best_pt.exists())
print('results.png exists:', results_png.exists())
print('results.csv exists:', results_csv.exists())

if results_png.exists():
    display(Image(filename=str(results_png)))

if results_csv.exists():
    df = pd.read_csv(results_csv)
    display(df.head())

    cols = [c for c in df.columns if c.lower() not in ['epoch', 'time']]
    x = df['epoch'] if 'epoch' in df.columns else range(len(df))

    to_plot = cols[:8]
    plt.figure()
    for c in to_plot:
        plt.plot(x, df[c], label=c)
    plt.xlabel('epoch')
    plt.legend()
    plt.title('Convergence curves (from results.csv)')
    plt.show()
else:
    print('æ‰¾ä¸åˆ° results.csvï¼›è«‹ç¢ºèª runs/ æ˜¯å¦æœ‰è¢«å¯«å…¥ /opt/ml/model/runs')

```

    Final status: Completed
    Model artifact: s3://2025team1/output/yolo11-train-1767630997/output/model.tar.gz
    Downloaded: artifacts/yolo11-train-1767630997/model.tar.gz
    best.pt exists: True
    results.png exists: True
    results.csv exists: True


> é€™ 10 å¼µåœ–çš„ x è»¸éƒ½æ˜¯ epochï¼ˆç¬¬å¹¾è¼ªè¨“ç·´ï¼‰ï¼Œy è»¸æ˜¯æå¤±æˆ–è©•ä¼°æŒ‡æ¨™çš„æ•¸å€¼ï¼›é‡é»æ˜¯çœ‹ã€Œè¨“ç·´ loss æœ‰æ²’æœ‰ä¸‹é™ã€é©—è­‰æŒ‡æ¨™ï¼ˆprecision / recall / mAPï¼‰æœ‰æ²’æœ‰ç©©å®šä¸Šå‡ä¸”ä¸ç™¼æ•£ã€ã€‚  
    1. y è»¸ï¼šBounding Box å›æ­¸èª¤å·®ï¼ˆä½ç½®æº–ä¸æº–ï¼‰(è¶Šä½è¶Šå¥½)  
    2. y è»¸ï¼šåˆ†é¡èª¤å·®ï¼ˆç‰©ä»¶æ˜¯ä»€éº¼é¡ï¼‰ (è¶Šä½è¶Šå¥½)
    3. ä¸‹æ’å·¦ä¸‰å¼µï¼šValidation Loss y è»¸ï¼šæ¨¡å‹åœ¨ã€Œæ²’çœ‹éçš„è³‡æ–™ã€ä¸Šçš„èª¤å·® (è¶Šä½è¶Šå¥½)  
    4. metrics/mAP50(B) åã€Œå¯¬é¬†ã€ï¼Œæ¥è¿‘å¯¦å‹™æ˜¯å¦æŠ“å¾—åˆ°
    5. metrics/mAP50-95(B) å¾ˆåš´æ ¼ï¼ˆæ¡†è¦å¾ˆæº–ï¼‰

![png](img/output_13_1.png)

| æª¢æŸ¥é …ç›®          | ä½ çš„çµæœ |
| ------------- | ---- |
| Train loss ä¸‹é™ | âœ…    |
| Val loss ä¸ç™¼æ•£  | âœ…    |
| Precision é«˜   | âœ…    |
| Recall é«˜      | âœ…    |
| mAP50 é«˜       | âœ…    |
| mAP50-95 ç©©å®š   | âœ…    |
| Overfitting   | âŒ æ²’æœ‰ |


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>epoch</th>
      <th>time</th>
      <th>train/box_loss</th>
      <th>train/cls_loss</th>
      <th>train/dfl_loss</th>
      <th>metrics/precision(B)</th>
      <th>metrics/recall(B)</th>
      <th>metrics/mAP50(B)</th>
      <th>metrics/mAP50-95(B)</th>
      <th>val/box_loss</th>
      <th>val/cls_loss</th>
      <th>val/dfl_loss</th>
      <th>lr/pg0</th>
      <th>lr/pg1</th>
      <th>lr/pg2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>3.36210</td>
      <td>0.64075</td>
      <td>3.11215</td>
      <td>1.11440</td>
      <td>0.00817</td>
      <td>1.00000</td>
      <td>0.84283</td>
      <td>0.75079</td>
      <td>0.35101</td>
      <td>3.10815</td>
      <td>0.85661</td>
      <td>0.000133</td>
      <td>0.000133</td>
      <td>0.000133</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>4.77159</td>
      <td>0.56221</td>
      <td>2.48942</td>
      <td>1.04130</td>
      <td>0.00801</td>
      <td>1.00000</td>
      <td>0.97753</td>
      <td>0.84357</td>
      <td>0.38801</td>
      <td>2.94903</td>
      <td>0.86088</td>
      <td>0.000278</td>
      <td>0.000278</td>
      <td>0.000278</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>6.14126</td>
      <td>0.65557</td>
      <td>1.94710</td>
      <td>1.08263</td>
      <td>0.00900</td>
      <td>1.00000</td>
      <td>0.97751</td>
      <td>0.83645</td>
      <td>0.47309</td>
      <td>2.79097</td>
      <td>0.89218</td>
      <td>0.000416</td>
      <td>0.000416</td>
      <td>0.000416</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>7.41680</td>
      <td>0.65320</td>
      <td>1.60130</td>
      <td>1.06209</td>
      <td>0.41777</td>
      <td>0.94872</td>
      <td>0.90134</td>
      <td>0.79629</td>
      <td>0.45788</td>
      <td>2.71875</td>
      <td>0.89499</td>
      <td>0.000549</td>
      <td>0.000549</td>
      <td>0.000549</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>8.71619</td>
      <td>0.67936</td>
      <td>1.43627</td>
      <td>1.08687</td>
      <td>1.00000</td>
      <td>0.26041</td>
      <td>0.72132</td>
      <td>0.58154</td>
      <td>0.67598</td>
      <td>2.75434</td>
      <td>1.06135</td>
      <td>0.000675</td>
      <td>0.000675</td>
      <td>0.000675</td>
    </tr>
  </tbody>
</table>
</div>



    
![png](img/output_13_3.png)
    


### 6) è¦–è¦ºåŒ–æ¨è«–ï¼ˆVisualized Inferenceï¼‰

- æœƒä½¿ç”¨ä¸‹è¼‰å¾Œçš„ `best.pt`
- å¾ä½ è§£å£“å¾Œçš„è³‡æ–™å¤¾ä¸­æ‰¾å¹¾å¼µ `val` å½±åƒåšæ¨è«–ä¸¦é¡¯ç¤º bbox

> æ³¨æ„ï¼šé€™æ ¼éœ€è¦ä½ å…ˆè·‘å®Œç¬¬ 5 æ ¼ï¼ˆå·²ä¸‹è¼‰ä¸¦è§£å£“ artifactsï¼‰ã€‚


```python
from ultralytics import YOLO
from pathlib import Path
import random
import matplotlib.pyplot as plt
from PIL import Image as PILImage

# ä¸‹è¼‰ä¸¦è§£å£“ datasetï¼ˆåªéœ€åšä¸€æ¬¡ï¼‰
from sagemaker.s3 import S3Downloader
from pathlib import Path
import zipfile

LOCAL_DATA_DIR = Path("dataset_local")
LOCAL_DATA_DIR.mkdir(exist_ok=True)

local_zip = LOCAL_DATA_DIR / DATA_ZIP_FILENAME

# å¾ S3 ä¸‹è¼‰ä½ è¨“ç·´ç”¨çš„ dataset zip
S3Downloader.download(S3_DATA_ZIP, str(LOCAL_DATA_DIR))

# è§£å£“
with zipfile.ZipFile(local_zip, "r") as z:
    z.extractall(LOCAL_DATA_DIR)

print("Dataset extracted to:", LOCAL_DATA_DIR)



# æ¨è«–æ¬Šé‡ï¼ˆç¬¬ 5 æ ¼è§£å£“å¾Œæ‡‰è©²å­˜åœ¨ï¼‰
weights = best_pt  # ç”±ç¬¬ 5 æ ¼å®šç¾©ï¼šout_dir/best.pt
assert Path(weights).exists(), f"best.pt not found: {weights}"

# å˜—è©¦å¾ artifacts æ—é‚Šæ‰¾åˆ°ä¸€æ‰¹ val images
# ä½ çš„ dataset zip å·²åœ¨è¨“ç·´å®¹å™¨å…§è§£å£“ï¼›é€™è£¡ Notebook ç«¯é€šå¸¸æ²’æœ‰ datasetã€‚
# å› æ­¤æˆ‘å€‘æ¡ç”¨å…©ç¨®ç­–ç•¥ï¼š
# 1) è‹¥ä½ æœ¬æ©Ÿ/Notebook æœ‰ datasetï¼ˆä¾‹å¦‚ä½ ä¹Ÿä¸‹è¼‰/è§£å£“åœ¨ workspaceï¼‰ï¼Œå°±ç”¨å®ƒ
# 2) å¦å‰‡ï¼šè«‹ä½ è‡ªè¡ŒæŒ‡å®š VAL_IMAGES_DIRï¼ˆä¸‹é¢æä¾›ç¯„ä¾‹ï¼‰

# ====== ä½ å¯ä»¥åœ¨é€™è£¡æŒ‡å®š val å½±åƒè³‡æ–™å¤¾ï¼ˆè‹¥è‡ªå‹•åµæ¸¬ä¸åˆ°ï¼‰======
VAL_IMAGES_DIR = "dataset_local/mydata/images/val"  # ä¾‹å¦‚: "mydata/images/val" æˆ– "/home/ec2-user/SageMaker/mydata/images/val"
# ============================================================

candidates = []

# (A) è‹¥ä½¿ç”¨è€…æŒ‡å®š
if VAL_IMAGES_DIR:
    p = Path(VAL_IMAGES_DIR)
    if p.exists():
        candidates += list(p.glob("*.jpg")) + list(p.glob("*.png"))

# (B) å˜—è©¦åœ¨ Notebook å·¥ä½œç›®éŒ„ä¸‹æ‰¾å¸¸è¦‹è·¯å¾‘
common_roots = [
    Path("."),
    Path("data"),
    Path("dataset"),
    Path("mydata"),
    Path("yolo_test_dataset"),
]
for r in common_roots:
    p = r / "mydata" / "images" / "val"
    if p.exists():
        candidates += list(p.glob("*.jpg")) + list(p.glob("*.png"))
    p2 = r / "images" / "val"
    if p2.exists():
        candidates += list(p2.glob("*.jpg")) + list(p2.glob("*.png"))

# å»é‡
candidates = sorted(set(candidates))

if not candidates:
    raise FileNotFoundError(
        "æ‰¾ä¸åˆ° val å½±åƒå¯è¦–è¦ºåŒ–æ¨è«–ã€‚"
        "è«‹æŠŠ VAL_IMAGES_DIR è¨­æˆä½ çš„ val å½±åƒè³‡æ–™å¤¾ï¼Œä¾‹å¦‚ï¼š"
        "VAL_IMAGES_DIR = 'mydata/images/val'"
    )

# æŠ½æ¨£å¹¾å¼µ
k = min(6, len(candidates))
sample_imgs = random.sample(candidates, k=k)
print("Using weights:", weights)
print("Visualizing", k, "images:")
for p in sample_imgs:
    print(" -", p)

model = YOLO(str(weights))

# é€å¼µæ¨è«–ä¸¦é¡¯ç¤ºï¼ˆUltralytics æœƒè¼¸å‡º results[0].plot() çš„ ndarrayï¼‰
for img_path in sample_imgs:
    results = model.predict(source=str(img_path), imgsz=IMGSZ, conf=0.01, verbose=False)
    r = results[0]
    print("Boxes:", r.boxes)
    if r.boxes is not None and len(r.boxes) > 0:
        print("xyxy:", r.boxes.xyxy.cpu().numpy())
        print("conf:", r.boxes.conf.cpu().numpy())
        print("cls :", r.boxes.cls.cpu().numpy())
    else:
        print("âŒ No detections")
    plotted = results[0].plot()  # numpy array (BGR)
    # BGR -> RGB for matplotlib
    plotted_rgb = plotted[..., ::-1]

    plt.figure(figsize=(6,6))
    plt.imshow(plotted_rgb)
    plt.axis("off")
    plt.title(f"Inference: {Path(img_path).name}")
    plt.show()

```

    Creating new Ultralytics Settings v0.0.6 file âœ… 
    View Ultralytics Settings with 'yolo settings' or at '/home/ec2-user/.config/Ultralytics/settings.json'
    Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.
    Dataset extracted to: dataset_local

![alt text](img/image7.png)

## Convert And Deploy
(Working in Progress)

![alt text](img/image8.png)

Use the following command to export the trained model to ONNX format:  
`python export_onnx.py --weights best.pt  --imgsz 640  --output yolo11n.onn`

```
[ec2-user@ip-172-21-70-48 models]$ pwd
/home/ec2-user/SageMaker/esp/esp-dev-kits/examples/esp32-p4-eye/examples/factory_demo/components/coco_detect/models
[ec2-user@ip-172-21-70-48 models]$ tree
.
â”œâ”€â”€ best.onnx.data
â”œâ”€â”€ best.pt
â”œâ”€â”€ export_onnx.py
â”œâ”€â”€ p4
â”‚   â”œâ”€â”€ coco_detect_yolo11n_320_s8_v3.espdl
â”‚   â”œâ”€â”€ coco_detect_yolo11n_s8_v1.espdl
â”‚   â”œâ”€â”€ coco_detect_yolo11n_s8_v2.espdl
â”‚   â””â”€â”€ coco_detect_yolo11n_s8_v3.espdl
â”œâ”€â”€ s3
â”‚   â”œâ”€â”€ coco_detect_yolo11n_320_s8_v3.espdl
â”‚   â”œâ”€â”€ coco_detect_yolo11n_s8_v1.espdl
â”‚   â”œâ”€â”€ coco_detect_yolo11n_s8_v2.espdl
â”‚   â””â”€â”€ coco_detect_yolo11n_s8_v3.espdl
â”œâ”€â”€ yolo11n.onnx
â”œâ”€â”€ yolo11n.onnx.bk260106
â””â”€â”€ yolo11n_320.onnx
```